#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import logging
import datetime
import shutil
import hashlib
import importlib.resources as resources

import click
from click_option_group import optgroup, RequiredMutuallyExclusiveOptionGroup
import pandas as pd

from pcalf.core import log 
from pcalf.workflow import HarleyDB
from pcalf.workflow import HarleySnake
from pcalf.workflow import wpcalf 
from pcalf.workflow import download




logger = logging.getLogger("pcalf-workflow")
logger.setLevel(logging.INFO)
console = logging.StreamHandler()
console.setLevel(logging.INFO)
console.setFormatter(log.CustomFormatter())
logger.addHandler(
    console
)
logger.propagate = False


@click.group()
def cli():
    """ """

@click.command()
@click.option('-t', '--taxid', "taxid", default = None , type=str , 
            help = "One ore more taxid seperated by a comma. \
                Mutually exclusive options with -a / --accession. [None]")
@click.option('-a',  "--accession" , "accession_file" , default=None , type=str , 
            help = "File with one NCBI assembly accession per line(e.g, GCA_937936705.1). \
                Mutually exclusive options with -t / --taxid. [None]")


@click.option('-e', '--exclude' , 'exclude', type=str, 
            help = "File with one NCBI accession that should be exclude from download. [None]")

@click.option('-o', '--outdir' , 'outdir', type=str,
            default = "./wpcalf",
            help = "Where results will be stored.")

@click.option('-g', '--group', "group_taxo", default="bacteria", 
              type=click.Choice(['all', 
                                'archaea', 
                                'bacteria', 
                                'fungi', 
                                'invertebrate', 
                                'metagenomes', 
                                'plant', 
                                'protozoa', 
                                'vertebrate_mammalian', 
                                'vertebrate_other', 
                                'viral'], case_sensitive=False), 
            help = "Taxonomic group, see ncbi-genome-download documentation \
                for details. [bacteria]")
@click.option('--snakargs','snakargs', type=str, 
              default="--printshellcmds -j1 --use-conda",
              help='Snakemake arguments.' )

def datasets(taxid, accession_file, exclude, outdir, group_taxo, snakargs ): 
    # Check input
    if (taxid is None and accession_file is None) or (taxid and accession_file):
        logger.error("You should specify at least one taxid [--taxid] or provide a file with one assembly accession per line. [--accession]")
        exit(-1)

    # CREATE DATAS DIRTECTORY
    outdir = os.path.abspath(outdir)
    os.makedirs(outdir,exist_ok=True)
    logger.info("Datas will be stored under {}".format(outdir))    

    # SETUP LOGGER
    harley_log_file = os.path.join(outdir,"download.log")
    fhandler = logging.FileHandler(harley_log_file)
    fhandler.setLevel(logging.INFO)    
    logger.addHandler(fhandler)   
    
    # MAKE CONFIG FILE    
    # Update Snakefile configuration with CLI values and run workflow.
    download_module_path = resources.files(download)
    download_module = HarleySnake.Snakemake(download_module_path)

    download_module.config["res_dir"] = str(outdir)
    download_module.config["taxid"] = int(taxid)
    download_module.config["include_accession"]= accession_file
    download_module.config["exclude_accession"]= exclude
    download_module.config["group"] = group_taxo

    configfile = os.path.join(outdir, "config.yaml")
    download_module.dump_config(configfile)
    snakargs = snakargs.split()
    snakargs.extend(["--configfile" , configfile])
    
    download_module.run(snakargs)


@click.command()
@click.option('-i', '--input' , 'input', required=True , type=str , 
            help = "Yaml file containing path to genome, cds_faa and cds_fna.")
@click.option('--db', 'db', type=None , 
            help = " explain here motherfucker...")
@click.option('-o', '--outdir' , 'outdir', required=True , type=str , 
            help = "Where datas such as checkm, gtdb-tk or pcalf results will be stored. Note that, for now,\
            the directory will not be remove if the workflow end correctly.")
@click.option("--gtdb" , "gtdb"  , default=None , type=str , 
            help = "path to GTDB. [None]")
@click.option("--checkm" , "checkm"  , default=None , type=str , 
            help = "path to checkm datas. [None]")
@click.option('-q', '--quick', "quick"  , default=False, is_flag=True , 
            help = ".. explain here .. [False]")
@click.option('--force', is_flag=True , 
           help= "Use this flag if you want to resume jobs from a specific instance. [False]" )
@click.option('--original', is_flag=True , 
            help = "Use original HMMs and N-ter files for pcalf. [False]")
#@click.option("--log" , "log"  , default=None , type=str , 
#            help = "logfile. [None]" )
@click.option('--snakargs','snakargs', type=str, default="",
            help='snakemake arguments. [None]' )
def run(input, db , outdir, gtdb , checkm , quick , force , original ,  snakargs ): 
    # Check input
    def validate_input(input):
        pass

    if os.path.exists(outdir) and not force:
        logger.error("{} output directory already exists.".format(outdir))
        exit(-1)
    else:
        outdir = os.path.abspath(outdir)
        os.makedirs(outdir , exist_ok=True)
    # SETUP LOGGER
    harley_log_file = os.path.join(outdir,"wpcalf.log")
    fhandler = logging.FileHandler(harley_log_file)
    fhandler.setLevel(logging.INFO)
    logger.addHandler(
        fhandler
    )   
    logger.info("wpcalf")
    logger.info("Output directory :  {}".format(outdir)) 

    # CREATE DB
    dbfile = os.path.join(outdir,"wpcalf.db")
    harleydb = HarleyDB.HarleyDB(dbfile)
    
    # Load external DB if provided
    glyx3 , gly1 , gly2, gly3 , nter = None, None, None, None, None


    def write_fasta(fastadict,file):
        os.makedirs(os.path.dirname(file),exist_ok=True)
        with open(file,'w') as fh:
            for seqid,sequence in fastadict.items():
                fh.write(">{}\n{}\n".format(seqid,sequence))
        return file

    if db:        
        logger.info("External DB : {}".format(db))
        logger.info("MSAs from {} will be used.".format(db))
        logger.info("Datas tables from {} will be included to final output.".format(db))
        externaldb = HarleyDB.HarleyDB(db)    
        # write MSAs to output directory:
        pcalfdatas = os.path.join(outdir,"pcalf_input_datas")
        gly1 = write_fasta(externaldb.to_msa("gly1"), os.path.join(pcalfdatas,"gly1.msa.fasta"))
        gly2 = write_fasta(externaldb.to_msa("gly2") , os.path.join(pcalfdatas,"gly2.msa.fasta"))
        gly3 = write_fasta(externaldb.to_msa("gly3") , os.path.join(pcalfdatas,"gly3.msa.fasta"))
        glyx3 = write_fasta(externaldb.to_msa("glyx3"), os.path.join(pcalfdatas,"glyx3.msa.fasta"))
        nter = os.path.join(pcalfdatas,"nter.tsv")
        pd.DataFrame(externaldb.generate_nter_db()).to_csv(nter,header=False,index=False,sep="\t")
        if not harleydb.is_same_schema(externaldb):
            logger.error("Current database schema is different from the schema of the external database you provide")
            exit(-1)

    if original:
        glyx3 , gly1 , gly2, gly3 , nter = None, None, None, None, None
    
    # MAKE CONFIG FILE    
    # Update Snakefile configuration with CLI values and run workflow.
    wpcalf_module_path = resources.files(wpcalf)
    wpcalf_module = HarleySnake.Snakemake(wpcalf_module_path)
    wpcalf_module.config["global"]["skip_genome_workflow"] = quick
    wpcalf_module.config["global"]["res_dir"] = outdir
    wpcalf_module.config["global"]["input"] = input

    if not quick:
        if not checkm or not gtdb or not os.path.isdir(checkm) or not os.path.isdir(gtdb):
            logger.error("GTDB and checkm datas should be specified. If you want to skip this part of the analysis use the --quick flag.")
            exit(-1)

    wpcalf_module.config["config-genomes"]["CheckM_data"] = checkm
    wpcalf_module.config["config-genomes"]["GTDB"] =  gtdb
    
    wpcalf_module.config["config-ccya"]["glyx3_msa"] = glyx3
    wpcalf_module.config["config-ccya"]["gly1_msa"]  = gly1
    wpcalf_module.config["config-ccya"]["gly2_msa"]  = gly2
    wpcalf_module.config["config-ccya"]["gly3_msa"]  = gly3
    wpcalf_module.config["config-ccya"]["nterdb"]    = nter

    configfile = os.path.join(outdir, "config.yaml")
    wpcalf_module.dump_config(configfile)
    snakargs = snakargs.split()
    snakargs.extend(["--configfile" , configfile])
    
    wpcalf_module.run(snakargs)

    ## EXPECTED OUTPUT FILES
    os.path.join(outdir,"pcalf","pcalf.summary.tsv")
    os.path.join(outdir,"pcalf","ccyA.summary.tsv")
    os.path.join(outdir,"pcalf","pcalf.features.tsv")
    os.path.join(outdir,"ncbi-datas","assembly_report.tsv")
    os.path.join(outdir,"checkm-res","tables","checkM_taxonomy.tsv") 
    os.path.join(outdir,"checkm-res","tables","checkM_statistics.tsv") 
    os.path.join(outdir,"checkm-res","tables","checkM_statistics_full.tsv")
    os.path.join(outdir,"gtdbtk-res","gtdbtk.ar53.bac120.summary.clean.tsv")

    
    # UPDATE DB
    
    #pcalf_features_table = os.path.join(outdir,"pcalf","pcalf.features.tsv")
    #pcalf_summary_table = os.path.join(outdir,"pcalf","pcalf.summary.tsv")
    #pcalf_ccya_summary_table = os.path.join(outdir,"pcalf","ccyA.summary.tsv")
    
    # gtdbtk_table = os.path.join(outdir,"gtdb-tk-res","gtdbtk.ar53.bac120.summary.clean.tsv")
    # checkm_stats_table = os.path.join(outdir,"checkm-res","tables", "checkM_statistics_full.tsv")
    # report_table = os.path.join(outdir,"datas","assemblies","report.tsv")

    # report_df = pt.read_table(report_table)
    # if report_df.empty:
    #     logger.error("Main genome table not found or empty :(.")
    #     exit(-1)
    # else:
    #     report_df['Download date'] = str(datetime.date.today()) 

    # pcalf_summary_df = pt.read_table(pcalf_summary_table)
    # if not pcalf_summary_df.empty:  
    #     # pcalf_summary_df = pd.DataFrame(columns=[
    #     #     "sequence_accession","sequence_src","flag","nter","nter_neighbor","cter","sequence","iteration"
    #     # ])                           
    #     logger.info("Seems we have caught something :)")        
    #     logger.info("No. of calcyanin detected: {}.".format(pcalf_summary_df.shape[0]))
    #     update_pcalf_datas = True
    # else:
    #     logger.warning("No calcyanin found :/")
    #     update_pcalf_datas = False
    
    # pcalf_summary_df.index.name = "sequence_id"
    # db.feed_db(pcalf_summary_df,"pcalf_summary","sequence_id")
    # report_df = pt.map_pcalf_results(report_df,pcalf_summary_df)
        
    # pcalf_features_df = pt.read_table(pcalf_features_table)
    # #if not pcalf_features_df.empty:     
    # pcalf_features_df.index.name = "sequence_id"
    # db.feed_db(pcalf_features_df,"pcalf_features","sequence_id")
        
    # ccya_df = pt.read_table(pcalf_ccya_summary_table)
    # #if not ccya_df.empty:        
    # ccya_df.index.name = "sequence_id"
    # db.feed_db(ccya_df,"ccya","sequence_id")
    
    # if update_pcalf_datas:        
    #     hash_object = hashlib.md5(str(datetime.datetime.now()).encode())    
    #     updated_pcalf_datas_dir = os.path.join(harleyconfig.dir , name ,"pcalf-datas",hash_object.hexdigest())
    #     os.makedirs(updated_pcalf_datas_dir, exist_ok=True )        
    #     logger.info("Copying new HMMs, new MSAs and new N-ter DB to {}.".format(updated_pcalf_datas_dir))
    #     shutil.copytree(os.path.join(outdir,"pcalf","HMM"), os.path.join(updated_pcalf_datas_dir,"HMM"),dirs_exist_ok=True)
    #     shutil.copytree(os.path.join(outdir,"pcalf","MSA"), os.path.join(updated_pcalf_datas_dir,"MSA"),dirs_exist_ok=True)
    #     shutil.copy(os.path.join(outdir,"pcalf","N-ter-DB.tsv"), os.path.join(updated_pcalf_datas_dir,"N-ter-DB.tsv"))
    #     logger.info("Done.")    
    #     # update pcalf datas to use with this <name> 
    #     db.glyx3 = os.path.join(updated_pcalf_datas_dir,"MSA","Glyx3.msa.fa")
    #     db.gly1 = os.path.join(updated_pcalf_datas_dir,"MSA","Gly1.msa.fa")
    #     db.gly2 = os.path.join(updated_pcalf_datas_dir,"MSA","Gly2.msa.fa")
    #     db.gly3 = os.path.join(updated_pcalf_datas_dir,"MSA","Gly3.msa.fa")
    #     db.nter = os.path.join(updated_pcalf_datas_dir,"N-ter-DB.tsv")


    # # Update genomes datas.    
    # # assembly_data_report.tsv file exists whatever the value of quick.
    # # If it's not a quick run then gtdb-tk and checkm files exists:
    # classi_df = pt.read_table(gtdbtk_table)
    # quality_df = pt.read_table(checkm_stats_table)

    # # We concatenate gtdb-tk and quality dfs
    # if not classi_df.empty and not quality_df.empty:
    #     genomes_df = pd.concat([quality_df,classi_df],axis=1)
    #     genomes_df.index.name="Assembly Accession"
    #     genomes_df['Genome size (Mp)'] = round(genomes_df["Genome size (bp)"]/1e6,2)
    #     # Save genome datas to database.
    #     logger.info("Feeding harley DB with genome quality and classification !")   
    #     db.feed_db(genomes_df,"genomes_detail","Assembly Accession")
    #     # Join some data to main genome table.        
    #     report_df = pd.concat(
    #         [report_df,
    #         genomes_df[["Genome size (Mp)" ,"# contigs", "N50 (contigs)", 
    #                     "Completeness","Contamination", "Strain heterogeneity",		
    #                     "classification", "fastani_reference"]]
    #         ],axis=1)            
    # else:
    #     # it's a quick run so gtdbtk and checkm results doesn't exists. Still, we create empty columns
    #     # for downstream analysis.
    #     report_df[["Genome size (Mp)" ,"# contigs", "N50 (contigs)", 
    #                 "Completeness","Contamination", "Strain heterogeneity",		
    #                 "classification", "fastani_reference"]] = None

    # # Feed the main genome table.
    # logger.info("Feeding harley DB main genome table  !")
    # report_df.index.name = "Assembly Accession"
    # db.feed_db(report_df,"genomes","Assembly Accession")

    # # Building report
    # report = Report()
    # report.make_report(db.dbfile,"/Users/mmillet/Documents/WORKS/SRC/WORKFLOWS/harley/report")
    # report.save(os.path.join(outdir , "report.html"))
    # logger.info("HTML report writen to {}.".format(os.path.join(outdir , "report.html")))
    # if shutil.which("open"):
    #     os.system("open {}".format( 
    #         os.path.join(outdir , "report.html")
    #     ))

    # # We save the updated config file and that's all
    # # ON SUCCESS ADD DB TO CONFIG 
    # db.add_run(HarleyRun(taxid,accession_file,outdir))   
    # harleyconfig.add_db(db)
    # harleyconfig.dump(hfile)
    # logger.info("End. Bye bye ! :) ")



cli.add_command(datasets)
cli.add_command(run)

if __name__ == '__main__':
    cli()         
